{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 23:25:17,099 :: INFO load_dataset :: [training] ../../datasets/BONE_CHANNELS/training\n",
      "2023-11-11 23:25:17,167 :: INFO load_dataset :: [training] ../../datasets/BONE_CHANNELS/training\n",
      "2023-11-11 23:25:17,233 :: INFO load_dataset :: [testing] ../../datasets/BONE_CHANNELS/testing\n",
      "2023-11-11 23:25:17,264 :: INFO create_dataloader :: Train images (640x640): 1258 augmentation: random\n",
      "2023-11-11 23:25:17,265 :: INFO create_dataloader :: Valid images (640x640): 315 augmentation: no_augmentation\n",
      "2023-11-11 23:25:17,265 :: INFO create_dataloader :: Test images (640x640): 464 augmentation: no_augmentation\n",
      "2023-11-11 23:25:17,266 :: INFO <module> :: 464\n",
      "2023-11-11 23:25:17,267 :: INFO <module> :: 1258\n"
     ]
    }
   ],
   "source": [
    "from bones_dataloader import *\n",
    "\n",
    "dataset_dir = \"../../datasets/BONE_CHANNELS\"\n",
    "\n",
    "batch_size = 6\n",
    "patch_size = (640, 640)\n",
    "color_model = \"RGB\"\n",
    "\n",
    "augmentation_strategy = \"random\" # \"no_augmentation\", \"color_augmentation\", \"inpainting_augmentation\", \"standard\", \"random\"\n",
    "augmentation = [None,\n",
    "                \"horizontal_flip\", \n",
    "                \"vertical_flip\", \n",
    "                \"rotation\", \n",
    "                \"transpose\", \n",
    "                \"elastic_transformation\", \n",
    "                \"grid_distortion\", \n",
    "                \"optical_distortion\",\n",
    "                #\"color_transfer\", \n",
    "                #\"inpainting\"]\n",
    "]\n",
    "\n",
    "dataloaders = create_dataloader(tile_size=\"{}x{}\".format(patch_size[0], patch_size[1]),\n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=True,\n",
    "                                img_input_size=patch_size,\n",
    "                                img_output_size=patch_size,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                color_model=color_model,\n",
    "                                augmentation=augmentation,\n",
    "                                augmentation_strategy=augmentation_strategy,\n",
    "                                start_epoch=1,\n",
    "                                validation_split=0.2)\n",
    "\n",
    "dataset_train_size = len(dataloaders['train'].dataset)\n",
    "dataset_test_size = len(dataloaders['test'].dataset)\n",
    "\n",
    "logger.info(dataset_test_size)\n",
    "logger.info(dataset_train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "percentage_inclusion_threshold = 0.7\n",
    "\n",
    "# Arquivo com as métricas médias para cada p\n",
    "csv_mean_file_path = '../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/canals/mean_quantitative_analysis.csv'\n",
    "mean_file = open(csv_mean_file_path, newline='', mode='w')\n",
    "mean_writer = csv.writer(mean_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "mean_writer.writerow(['prob_threshold', 'accuracy', 'precision', 'f1/dice', 'sensitivity/recall', 'tp', 'tn', 'fp'])\n",
    "\n",
    "set_size = len(dataloaders['test'].dataset.samples)\n",
    "\n",
    "for threshold_prob in np.arange(0.0,1.0,0.05):\n",
    "    csv_file_path = f'../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/canals/quantitative_analysis_{\"%.3f\" % threshold_prob}.csv'\n",
    "\n",
    "    sum_accuracy = 0\n",
    "    sum_precision = 0\n",
    "    sum_f1 = 0\n",
    "    sum_recall = 0\n",
    "    sum_vp = 0\n",
    "    sum_vn = 0\n",
    "    sum_fp = 0\n",
    "\n",
    "    with open(csv_file_path, newline='', mode='w') as medidas_file:\n",
    "        medidas_writer = csv.writer(medidas_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        medidas_writer.writerow(['wsi_image', 'accuracy', 'precision', 'f1/dice', 'sensitivity/recall', 'tp', 'tn', 'fp'])\n",
    "\n",
    "\n",
    "        for image in range(set_size):\n",
    "        \n",
    "            # Verdadeiros positivos (São canais e foram segmentados como canais)\n",
    "            vp = 0\n",
    "            # Verdadeiros negativos (São canais mas não foram segmentados como canais)\n",
    "            vn = 0\n",
    "            # Falsos positivos (Não são canais mas foram segmentados como canais)\n",
    "            fp = 0\n",
    "    \n",
    "            original_mask   = Image.open(dataloaders['test'].dataset.samples[image][1])\n",
    "            fname = dataloaders['test'].dataset.samples[image][1].split('\\\\')[1]\n",
    "            segmented_mask  = Image.open(f'../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/bones/patch/640x640/binary_images/prob_{\"%.3f\" % threshold_prob}/{fname}')\n",
    "    \n",
    "            original_mask_np = np.array(original_mask)\n",
    "            segmented_mask_np = np.array(segmented_mask)[:, :, 0]\n",
    "    \n",
    "            already_processed_components = []\n",
    "            labeled_original_mask, nr_original_objects = ndimage.label(original_mask_np != 0.)\n",
    "            original_mask_props = regionprops(labeled_original_mask)\n",
    "    \n",
    "            labeled_segmented_mask, nr_segmented_objects = ndimage.label(segmented_mask_np != 0.)\n",
    "    \n",
    "            for prop_idx in range(len(original_mask_props)):\n",
    "                ## Calcula verdadeiros positivos e negativos\n",
    "                [X, Y, x, y] = original_mask_props[prop_idx].bbox  \n",
    "    \n",
    "                bitwised = np.bitwise_and(original_mask_np[X:x, Y:y], segmented_mask_np[X:x, Y:y])\n",
    "                #plt.imshow(original_mask_np[X:x, Y:y])\n",
    "                #plt.show()\n",
    "                #plt.imshow(segmented_mask_np[X:x, Y:y])\n",
    "                #plt.show()  \n",
    "                #plt.imshow(bitwised)\n",
    "                #plt.show()  \n",
    "    \n",
    "                count_original = np.count_nonzero(original_mask_np[X:x, Y:y])\n",
    "                count_intersection = np.count_nonzero(bitwised) \n",
    "                percent_included = abs(count_intersection/count_original) \n",
    "    \n",
    "                if percent_included >= percentage_inclusion_threshold:\n",
    "                    vp = vp + 1\n",
    "    \n",
    "                    ## Armazena relações de labels\n",
    "                    bbox_labeled = labeled_original_mask[X:x, Y:y]\n",
    "                    a = np.nonzero(bbox_labeled)[0][0]\n",
    "                    b = np.nonzero(bbox_labeled)[1][0]\n",
    "                    original_mask_label = bbox_labeled[a][b]\n",
    "    \n",
    "                    bbox_labeled = labeled_segmented_mask[X:x, Y:y]\n",
    "                    a = np.nonzero(bbox_labeled)[0][0]\n",
    "                    b = np.nonzero(bbox_labeled)[1][0]\n",
    "                    segmented_mask_label = bbox_labeled[a][b]\n",
    "                    already_processed_components.append((original_mask_label, segmented_mask_label))\n",
    "                else:\n",
    "                    vn = vn + 1\n",
    "                    bbox_labeled = labeled_original_mask[X:x, Y:y]\n",
    "                    a = np.nonzero(bbox_labeled)[0][0]\n",
    "                    b = np.nonzero(bbox_labeled)[1][0]\n",
    "                    original_mask_label = bbox_labeled[a][b]\n",
    "                    already_processed_components.append((original_mask_label, None))\n",
    "    \n",
    "            segmented_mask_props = regionprops(labeled_segmented_mask)\n",
    "    \n",
    "            for prop_idx in range(len(segmented_mask_props)):\n",
    "                ## Verifica se componente já foi processado\n",
    "                [X, Y, x, y] = segmented_mask_props[prop_idx].bbox\n",
    "                bbox_labeled = labeled_segmented_mask[X:x, Y:y]\n",
    "                a = np.nonzero(bbox_labeled)[0][0]\n",
    "                b = np.nonzero(bbox_labeled)[1][0]\n",
    "                current_component_label = bbox_labeled[a][b]\n",
    "                alread_processed = False\n",
    "    \n",
    "                for i in already_processed_components:\n",
    "                    if i[1] == current_component_label:\n",
    "                        alread_processed = True\n",
    "                        break\n",
    "                    \n",
    "                if alread_processed:\n",
    "                    break\n",
    "                \n",
    "                fp = fp + 1\n",
    "                already_processed_components.append((None, current_component_label))\n",
    "    \n",
    "            #print('Verdadeiros positivos: ' + str(vp))\n",
    "            #print('Verdadeiros negativos: ' + str(vn))\n",
    "            #print('Falsos positivos: ' + str(fp))\n",
    "    \n",
    "            if vp == 0:\n",
    "                precision = 0\n",
    "                recall = 0\n",
    "                f1 = 0\n",
    "                accuracy = 0    \n",
    "            else:\n",
    "                precision = vp/(vp + fp)\n",
    "                recall = vp/(vp + vn)\n",
    "                f1 = (2*precision*recall)/(precision + recall)\n",
    "                accuracy = vp/(vp + vn + fp)\n",
    "    \n",
    "            #print('Acurácia: ' + str(accuracy))\n",
    "            #print('Sensibilidade: ' + str(recall))\n",
    "            #print('Precisão: ' + str(precision))\n",
    "            #print('F1-Score: ' + str(f1))\n",
    "    \n",
    "            # escreve linha no arquivo local\n",
    "            medidas_writer.writerow([fname, accuracy, precision, f1, recall, vp, vn, fp])\n",
    "        sum_accuracy = sum_accuracy + accuracy\n",
    "        sum_precision = sum_precision + precision\n",
    "        sum_f1 = sum_f1 + f1\n",
    "        sum_recall = sum_recall + recall\n",
    "        sum_vp = sum_vp + vp\n",
    "        sum_vn = sum_vn + vn\n",
    "        sum_fp = sum_fp + fp\n",
    "\n",
    "    # escreve linha no arquivo de medias\n",
    "    mean_writer.writerow([threshold_prob, sum_accuracy/set_size, sum_precision/set_size, sum_f1/set_size, sum_recall/set_size, sum_vp/set_size, sum_vn/set_size, sum_fp/set_size])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "\n",
    "probability_threshold_selected = 0.4\n",
    "percentage_inclusion_threshold = 0.7\n",
    "# Verdadeiros positivos (São canais e foram segmentados como canais)\n",
    "vp = 0\n",
    "# Verdadeiros negativos (São canais mas não foram segmentados como canais)\n",
    "vn = 0\n",
    "# Falsos positivos (Não são canais mas foram segmentados como canais)\n",
    "fp = 0\n",
    "\n",
    "for image in range(set_size):\n",
    "\n",
    "    original_mask   = Image.open(dataloaders['test'].dataset.samples[image][1])\n",
    "    fname = dataloaders['test'].dataset.samples[image][1].split('\\\\')[1]\n",
    "    segmented_mask  = Image.open(f'../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/bones/patch/640x640/binary_images/{\"%.3f\" % probability_threshold_selected}/{fname}')\n",
    "    original_mask_np = np.array(original_mask)\n",
    "    segmented_mask_np = np.array(segmented_mask)[:, :, 0]\n",
    "    already_processed_components = []\n",
    "    labeled_original_mask, nr_original_objects = ndimage.label(original_mask_np != 0.)\n",
    "    original_mask_props = regionprops(labeled_original_mask)\n",
    "    labeled_segmented_mask, nr_segmented_objects = ndimage.label(segmented_mask_np != 0.)\n",
    "    for prop_idx in range(len(original_mask_props)):\n",
    "        ## Calcula verdadeiros positivos e negativos\n",
    "        [X, Y, x, y] = original_mask_props[prop_idx].bbox  \n",
    "        bitwised = np.bitwise_and(original_mask_np[X:x, Y:y], segmented_mask_np[X:x, Y:y])\n",
    "        #plt.imshow(original_mask_np[X:x, Y:y])\n",
    "        #plt.show()\n",
    "        #plt.imshow(segmented_mask_np[X:x, Y:y])\n",
    "        #plt.show()  \n",
    "        #plt.imshow(bitwised)\n",
    "        #plt.show()  \n",
    "        count_original = np.count_nonzero(original_mask_np[X:x, Y:y])\n",
    "        count_intersection = np.count_nonzero(bitwised) \n",
    "        percent_included = abs(count_intersection/count_original) \n",
    "        if percent_included >= percentage_inclusion_threshold:\n",
    "            vp = vp + 1\n",
    "            ## Armazena relações de labels\n",
    "            bbox_labeled = labeled_original_mask[X:x, Y:y]\n",
    "            a = np.nonzero(bbox_labeled)[0][0]\n",
    "            b = np.nonzero(bbox_labeled)[1][0]\n",
    "            original_mask_label = bbox_labeled[a][b]\n",
    "            bbox_labeled = labeled_segmented_mask[X:x, Y:y]\n",
    "            a = np.nonzero(bbox_labeled)[0][0]\n",
    "            b = np.nonzero(bbox_labeled)[1][0]\n",
    "            segmented_mask_label = bbox_labeled[a][b]\n",
    "            already_processed_components.append((original_mask_label, segmented_mask_label))\n",
    "        else:\n",
    "            vn = vn + 1\n",
    "            bbox_labeled = labeled_original_mask[X:x, Y:y]\n",
    "            a = np.nonzero(bbox_labeled)[0][0]\n",
    "            b = np.nonzero(bbox_labeled)[1][0]\n",
    "            original_mask_label = bbox_labeled[a][b]\n",
    "            already_processed_components.append((original_mask_label, None))\n",
    "    segmented_mask_props = regionprops(labeled_segmented_mask)\n",
    "    for prop_idx in range(len(segmented_mask_props)):\n",
    "        ## Verifica se componente já foi processado\n",
    "        [X, Y, x, y] = segmented_mask_props[prop_idx].bbox\n",
    "        bbox_labeled = labeled_segmented_mask[X:x, Y:y]\n",
    "        a = np.nonzero(bbox_labeled)[0][0]\n",
    "        b = np.nonzero(bbox_labeled)[1][0]\n",
    "        current_component_label = bbox_labeled[a][b]\n",
    "        alread_processed = False\n",
    "        for i in already_processed_components:\n",
    "            if i[1] == current_component_label:\n",
    "                alread_processed = True\n",
    "                break\n",
    "        if alread_processed:\n",
    "            break\n",
    "        fp = fp + 1\n",
    "        already_processed_components.append((None, current_component_label))\n",
    "\n",
    "\n",
    "print('Verdadeiros positivos: ' + str(vp))\n",
    "print('Verdadeiros negativos: ' + str(vn))\n",
    "print('Falsos positivos: ' + str(fp))\n",
    "precision = vp/(vp + fp)\n",
    "recall = vp/(vp + vn)\n",
    "f1 = (2*precision*recall)/(precision + recall)\n",
    "accuracy = vp/(vp + vn + fp)\n",
    "print('Acurácia: ' + str(accuracy))\n",
    "print('Sensibilidade: ' + str(recall))\n",
    "print('Precisão: ' + str(precision))\n",
    "print('F1-Score: ' + str(f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
