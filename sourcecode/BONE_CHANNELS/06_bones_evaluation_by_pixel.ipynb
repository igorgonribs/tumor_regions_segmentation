{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative metrics for image-patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "\n",
    "current_path = os.path.abspath('.')\n",
    "root_path = os.path.dirname(os.path.dirname(current_path))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from sourcecode.BONE_CHANNELS.bones_dataloader import *\n",
    "from sourcecode.wsi_image_utils import *\n",
    "from sourcecode.evaluation_utils import *\n",
    "\n",
    "number_epoches = 100\n",
    "dataset_name = \"BONE_CHANNELS\"\n",
    "dataset_dir = \"../../datasets/\" + dataset_name\n",
    "batch_size = 1\n",
    "patch_size = 640\n",
    "patch_size_tuple = (patch_size, patch_size)\n",
    "color_model = \"LAB\"\n",
    "class_name = \"bones\"\n",
    "dataloaders = create_dataloader(tile_size=\"{}x{}\".format(patch_size, patch_size),\n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False,\n",
    "                                img_input_size=patch_size_tuple,\n",
    "                                img_output_size=patch_size_tuple,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                color_model=color_model)\n",
    "\n",
    "dataset_train_size = len(dataloaders['train'].dataset)\n",
    "dataset_test_size = len(dataloaders['test'].dataset)\n",
    "print(\"-\")\n",
    "\n",
    "tile_size = 20\n",
    "magnification=0.625\n",
    "\n",
    "threshold_itc = 200/(0.243 * pow(2, 5))\n",
    "\n",
    "#wsi_images_dir_normal = \"{}/testing/normal/wsi\".format(dataset_dir)\n",
    "wsi_images_dir_tumor = \"{}/testing/bones\".format(dataset_dir)\n",
    "\n",
    "trained_model_version = f\"{dataset_name}__Size-{patch_size}x{patch_size}_Epoch-{number_epoches}_Images-{dataset_test_size}_Batch-1__random_distortion\"\n",
    "results_dir=\"{}/results/{}/testing\".format(dataset_dir, trained_model_version)\n",
    "\n",
    "# Arquivo com as métricas médias para cada p\n",
    "csv_mean_file_path = \"{}/pixels/mean_quantitative_analysis.csv\".format(results_dir)\n",
    "mean_file = open(csv_mean_file_path, newline='', mode='w')\n",
    "mean_writer = csv.writer(mean_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "mean_writer.writerow(['wsi_image', 'class', 'mean auc', 'mean accuracy', 'mean precision', 'mean f1/dice', 'mean jaccard', 'mean sensitivity/recall', 'mean specificity', 'mean tp', 'mean tn', 'mean fp', 'mean fn'])\n",
    "\n",
    "wsi_tissue_patches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fill_contours(arr):\n",
    "    return np.maximum.accumulate(arr,1) & np.maximum.accumulate(arr[:,::-1],1)[:,::-1]\n",
    "\n",
    "def get_mean_props_area(RGBna):\n",
    "    labeled, nr_objects = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    if nr_objects == 0:\n",
    "        return 0\n",
    "    \n",
    "    mean_props_area = 0\n",
    "    for prop in range(len(props)):\n",
    "        mean_props_area = mean_props_area + props[prop].area\n",
    "    \n",
    "    mean_props_area = mean_props_area/len(props)\n",
    "    return mean_props_area\n",
    "\n",
    "# Remove ruídos  \n",
    "def remove_noise(RGBna, mean_props_area):\n",
    "    labeled, _ = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    new_mask = np.copy(RGBna)\n",
    "    \n",
    "    for prop in range(len(props)):\n",
    "        if props[prop].area > (0.1)*mean_props_area:\n",
    "            continue\n",
    "        else:\n",
    "            [X, Y, x, y] = props[prop].bbox\n",
    "            new_mask[X:x, Y:y] = props[prop].image_filled.astype(np.uint8)*0\n",
    "       \n",
    "            \n",
    "    #plt.imshow(new_mask)#Image.fromarray(new_mask).show()\n",
    "    return new_mask\n",
    "\n",
    "# Preenche contornos  \n",
    "def fill_components_contours(RGBna):\n",
    "    labeled, nr_objects = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    new_mask = np.copy(RGBna)\n",
    "\n",
    "    for prop in range(len(props)):\n",
    "        [X, Y, x, y] = props[prop].bbox\n",
    "        new_mask[X:x, Y:y] = fill_contours(props[prop].image_filled.astype(np.uint8)*255)\n",
    "\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation varying p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold_prob in np.arange(0.0,1.0,0.05):\n",
    "    csv_file_path = f'{results_dir}/pixels/quantitative_analysis_{\"%.3f\" % threshold_prob}.csv'\n",
    "\n",
    "    wsi_tissue_patches = {}\n",
    "    with open(csv_file_path, newline='', mode='w') as medidas_file:\n",
    "        medidas_writer = csv.writer(medidas_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        medidas_writer.writerow(['wsi_image', 'patch_image', 'auc', 'accuracy', 'precision', 'f1/dice', 'jaccard', 'sensitivity/recall', 'specificity', 'pixels', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "        for batch_idx, (data, target, fname, original_size) in enumerate(dataloaders['test']):\n",
    "\n",
    "            sum_auc = 0.0 \n",
    "            sum_accuracy = 0.0 \n",
    "            sum_precision = 0.0 \n",
    "            sum_f1 = 0.0 \n",
    "            sum_jaccard = 0.0\n",
    "            sum_recall = 0.0\n",
    "            sum_specificity = 0.0\n",
    "            sum_tp = 0.0\n",
    "            sum_tn = 0.0\n",
    "            sum_fp = 0.0\n",
    "            sum_fn = 0.0\n",
    "\n",
    "            # wsi image number\n",
    "            wsi_image_number = fname[0].split(\"_\")[0]\n",
    "            if wsi_image_number not in wsi_tissue_patches:\n",
    "\n",
    "                # extract the tissue region from original image and draw the heat grid\n",
    "                wsi_image_path = \"{}/{}.png\".format(wsi_images_dir_tumor, wsi_image_number)\n",
    "                #if not os.path.exists(wsi_image_path):\n",
    "                #    wsi_image_path = \"{}/{}.tif\".format(wsi_images_dir_normal, wsi_image_number)\n",
    "\n",
    "                 # scale down image\n",
    "                print(wsi_image_path)\n",
    "                wsi_image = open_wsi(wsi_image_path)\n",
    "                pil_scaled_down_image = scale_down_wsi(wsi_image, magnification, False)\n",
    "                np_scaled_down_image = pil_to_np(pil_scaled_down_image)\n",
    "\n",
    "                # extract tissue region \n",
    "                np_tissue_mask, np_masked_image = extract_normal_region_from_wsi(wsi_image_path, np_scaled_down_image, None)\n",
    "                pil_masked_image = np_to_pil(np_masked_image)\n",
    "\n",
    "                # draw the heat grid\n",
    "                pil_img_result, heat_grid, number_of_tiles = draw_heat_grid(np_masked_image, tile_size)\n",
    "\n",
    "                tissue_patches = []\n",
    "                for idx, (position, row, column, location, size, color) in enumerate(heat_grid):\n",
    "                    if color != GREEN_COLOR: \n",
    "                        tissue_patches.append(\"{}_r{}c{}.png\".format(wsi_image_number, row, column))\n",
    "\n",
    "                wsi_tissue_patches[wsi_image_number] = tissue_patches\n",
    "                #print(wsi_tissue_patches)\n",
    "\n",
    "            # check if the patch was excluded in preprocessing step\n",
    "            patch_excludde_in_preprocessing = fname[0] not in wsi_tissue_patches[wsi_image_number]\n",
    "\n",
    "            # load the mask image\n",
    "            mask_np_img = target[0].numpy()\n",
    "\n",
    "            # roi x non_roi classes\n",
    "            wsi_class = class_name if wsi_image_path.find(class_name) > 0 else \"normal\"\n",
    "            patch_class = \"roi\" if np.max(np.unique(mask_np_img)) > 0 else 'non_roi'\n",
    "\n",
    "\n",
    "            # load the predicted image result\n",
    "            patch_results_dir = \"{}/{}/patch/{}x{}/{}\".format(results_dir, wsi_class, patch_size, patch_size, fname[0])\n",
    "            print(\"Patch results dir: \" + patch_results_dir)\n",
    "            unet_result_img = \"{}/01-unet_result/{}\".format(patch_results_dir, fname[0])\n",
    "            predicted_pil_img = Image.fromarray(np.zeros(mask_np_img.shape)) if patch_excludde_in_preprocessing else load_pil_image(unet_result_img, gray=True) if os.path.isfile(unet_result_img) else Image.fromarray(np.zeros(mask_np_img.shape))\n",
    "            predicted_np_img = np.copy(pil_to_np(predicted_pil_img)) \n",
    "            predicted_np_img = predicted_np_img * (1.0/255)\n",
    "            predicted_np_img = basic_threshold(predicted_np_img, threshold=threshold_prob, output_type=\"float\")\n",
    "\n",
    "            predicted_labels = measure.label(predicted_np_img, connectivity=2)\n",
    "            #predicted_np_img = np.zeros((predicted_np_img.shape[0], predicted_np_img.shape[1]))\n",
    "            #labels = np.unique(predicted_labels)\n",
    "            #properties = measure.regionprops(predicted_labels)\n",
    "            #for lbl in range(1, np.max(labels)):\n",
    "            #    major_axis_length = properties[lbl-1].major_axis_length\n",
    "            #    if major_axis_length > threshold_itc:\n",
    "            #        predicted_np_img[predicted_labels == lbl] = 1\n",
    "\n",
    "            # SAVE BINARY IMAGES\n",
    "            bin_images_path = f'../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/bones/patch/640x640/binary_images/prob_{\"%.3f\" % threshold_prob}/'\n",
    "            if not os.path.isdir(bin_images_path):\n",
    "                os.mkdir(bin_images_path)\n",
    "\n",
    "            predicted_np_img_255 = predicted_np_img * 255\n",
    "            mean = get_mean_props_area(predicted_np_img_255)\n",
    "            predicted_np_img_255 = remove_noise(predicted_np_img_255, mean)\n",
    "            predicted_np_img_255 = fill_components_contours(predicted_np_img_255)\n",
    "    \n",
    "            new_p = Image.fromarray(predicted_np_img_255)\n",
    "            if new_p.mode != 'RGB':\n",
    "                new_p = new_p.convert('RGB')\n",
    "            new_p.save(bin_images_path + fname[0])\n",
    "\n",
    "            # metrics\n",
    "            auc = roc_auc_score(mask_np_img, predicted_np_img)\n",
    "            precision = precision_score(mask_np_img, predicted_np_img)\n",
    "            recall = recall_score(mask_np_img, predicted_np_img)\n",
    "            accuracy = accuracy_score(mask_np_img, predicted_np_img)\n",
    "            f1 = f1_score(mask_np_img, predicted_np_img)\n",
    "            specificity = specificity_score(mask_np_img, predicted_np_img)\n",
    "            jaccard = jaccard_score(mask_np_img, predicted_np_img)\n",
    "\n",
    "            total_pixels, tn, fp, fn, tp = tn_fp_fn_tp(mask_np_img, predicted_np_img)\n",
    "\n",
    "            print(\"Results for {:26} ({:7} - {:8} - {:04.2f} accuracy)\".format(fname[0].split(\"_\")[1], patch_class, \"excluded\" if patch_excludde_in_preprocessing else \"unet\", accuracy))\n",
    "            print(\"   Precision: \\t{}\".format(precision))\n",
    "            print(\"   Recall/Sen: \\t{}\".format(recall))\n",
    "            print(\"   F1/Dice: \\t{}\".format(f1))\n",
    "            print(\"   Accuracy: \\t{}\".format(accuracy))\n",
    "            print(\"   Specificity: {}\".format(specificity))\n",
    "            print(\"   Jaccard: \\t{}\".format(jaccard))\n",
    "            print(\"   TP = {} TN = {} FP = {} FN = {}\".format(tp, tn, fp, fn))\n",
    "            print(\"-\")\n",
    "\n",
    "            medidas_writer.writerow([wsi_image_number, patch_class, auc, accuracy, precision, f1, jaccard, recall, specificity, total_pixels, tp, tn, fp, fn])\n",
    "\n",
    "            sum_auc = sum_auc + auc \n",
    "            sum_accuracy = sum_accuracy + accuracy\n",
    "            sum_precision = sum_precision + precision \n",
    "            sum_f1 = sum_f1 + f1\n",
    "            sum_jaccard = sum_jaccard + jaccard\n",
    "            sum_recall = sum_recall + recall\n",
    "            sum_specificity = sum_specificity + specificity\n",
    "            sum_tp = sum_tp + tp\n",
    "            sum_tn = sum_tn + tn\n",
    "            sum_fp = sum_fp + fp\n",
    "            sum_fn = sum_fn + fn\n",
    "            \n",
    "    mean_writer.writerow([wsi_image_number, \n",
    "                          patch_class, \n",
    "                          sum_auc/dataset_test_size, \n",
    "                          sum_accuracy/dataset_test_size, \n",
    "                          sum_precision/dataset_test_size, \n",
    "                          sum_f1/dataset_test_size, \n",
    "                          sum_jaccard/dataset_test_size,\n",
    "                          sum_recall/dataset_test_size,\n",
    "                          sum_specificity/dataset_test_size,\n",
    "                          sum_tp/dataset_test_size,\n",
    "                          sum_tn/dataset_test_size,\n",
    "                          sum_fp/dataset_test_size,\n",
    "                          sum_fn/dataset_test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantitative_analysis_0.000.csv\n",
      "quantitative_analysis_0.050.csv\n",
      "quantitative_analysis_0.100.csv\n",
      "quantitative_analysis_0.150.csv\n",
      "quantitative_analysis_0.200.csv\n",
      "quantitative_analysis_0.250.csv\n",
      "quantitative_analysis_0.300.csv\n",
      "quantitative_analysis_0.350.csv\n",
      "quantitative_analysis_0.400.csv\n",
      "quantitative_analysis_0.450.csv\n",
      "quantitative_analysis_0.500.csv\n",
      "quantitative_analysis_0.550.csv\n",
      "quantitative_analysis_0.600.csv\n",
      "quantitative_analysis_0.650.csv\n",
      "quantitative_analysis_0.700.csv\n",
      "quantitative_analysis_0.750.csv\n",
      "quantitative_analysis_0.800.csv\n",
      "quantitative_analysis_0.850.csv\n",
      "quantitative_analysis_0.900.csv\n",
      "quantitative_analysis_0.950.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dir = f'../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/pixels/'\n",
    "files = os.listdir(dir)\n",
    "\n",
    "means_matrix = np.zeros((20, 12))\n",
    "for idx in range(len(files)):\n",
    "    if os.path.isdir(dir + files[idx]):\n",
    "        continue\n",
    "    \n",
    "    print(files[idx])\n",
    "    my_data = np.genfromtxt(dir + files[idx], delimiter=',')\n",
    "\n",
    "    my_data = np.delete(my_data, 0, 0)\n",
    "    my_data = np.delete(my_data, 0, 1)\n",
    "    my_data = np.delete(my_data, 0, 1)\n",
    "\n",
    "    means_row = []\n",
    "    for col in range(len(my_data[0,:])):\n",
    "        means_row.append(np.sum(my_data[:,col])/(len(my_data[:,col])))\n",
    "\n",
    "    means_matrix[idx,:] = np.array(means_row)\n",
    "\n",
    "np.round(means_matrix, 3, means_matrix)\n",
    "df = pd.DataFrame(means_matrix)\n",
    "df['file'] = files\n",
    "# Save DataFrame to .csv\n",
    "df.to_csv(dir + 'means.csv', index=False, header=['auc', 'accuracy', 'precision', 'f1/dice', 'jaccard', 'sensitivity/recall', 'specificity', 'pixels', 'tp', 'tn', 'fp', 'fn', 'file'])\n",
    "#print(means_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate masks for best p (0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fill_contours(arr):\n",
    "    return np.maximum.accumulate(arr,1) & np.maximum.accumulate(arr[:,::-1],1)[:,::-1]\n",
    "\n",
    "def get_mean_props_area(RGBna):\n",
    "    labeled, nr_objects = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    new_mask = np.copy(RGBna)\n",
    "    mean_props_area = 0\n",
    "    for prop in range(len(props)):\n",
    "        mean_props_area = mean_props_area + props[prop].area\n",
    "    \n",
    "    mean_props_area = mean_props_area/len(props)\n",
    "    return mean_props_area\n",
    "\n",
    "# Remove ruídos  \n",
    "def remove_noise(RGBna, mean_props_area):\n",
    "    labeled, _ = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    new_mask = np.copy(RGBna)\n",
    "    \n",
    "    for prop in range(len(props)):\n",
    "        if props[prop].area > (0.1)*mean_props_area:\n",
    "            continue\n",
    "        else:\n",
    "            [X, Y, x, y] = props[prop].bbox\n",
    "            new_mask[X:x, Y:y] = props[prop].image_filled.astype(np.uint8)*0\n",
    "       \n",
    "            \n",
    "    #plt.imshow(new_mask)#Image.fromarray(new_mask).show()\n",
    "    return new_mask\n",
    "\n",
    "# Preenche contornos  \n",
    "def fill_components_contours(RGBna):\n",
    "    labeled, nr_objects = ndimage.label(RGBna != 0.) \n",
    "    props = regionprops(labeled)\n",
    "\n",
    "    new_mask = np.copy(RGBna)\n",
    "\n",
    "    for prop in range(len(props)):\n",
    "        [X, Y, x, y] = props[prop].bbox\n",
    "        new_mask[X:x, Y:y] = fill_contours(props[prop].image_filled.astype(np.uint8)*255)\n",
    "\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_prob = 0.4\n",
    "\n",
    "for batch_idx, (data, target, fname, original_size) in enumerate(dataloaders['test']):\n",
    "    # wsi image number\n",
    "    wsi_image_number = fname[0].split(\"_\")[0]\n",
    "    if wsi_image_number not in wsi_tissue_patches:\n",
    "        # extract the tissue region from original image and draw the heat grid\n",
    "        wsi_image_path = \"{}/{}.png\".format(wsi_images_dir_tumor, wsi_image_number)\n",
    "        wsi_image = open_wsi(wsi_image_path)\n",
    "        pil_scaled_down_image = scale_down_wsi(wsi_image, magnification, False)\n",
    "        np_scaled_down_image = pil_to_np(pil_scaled_down_image)\n",
    "        # extract tissue region \n",
    "        np_tissue_mask, np_masked_image = extract_normal_region_from_wsi(wsi_image_path, np_scaled_down_image, None)\n",
    "        pil_masked_image = np_to_pil(np_masked_image)\n",
    "        # draw the heat grid\n",
    "        pil_img_result, heat_grid, number_of_tiles = draw_heat_grid(np_masked_image, tile_size)\n",
    "        tissue_patches = []\n",
    "        for idx, (position, row, column, location, size, color) in enumerate(heat_grid):\n",
    "            if color != GREEN_COLOR: \n",
    "                tissue_patches.append(\"{}_r{}c{}.png\".format(wsi_image_number, row, column))\n",
    "        wsi_tissue_patches[wsi_image_number] = tissue_patches\n",
    "        #print(wsi_tissue_patches)\n",
    "    # check if the patch was excluded in preprocessing step\n",
    "    patch_excludde_in_preprocessing = fname[0] not in wsi_tissue_patches[wsi_image_number]\n",
    "    # load the mask image\n",
    "    mask_np_img = target[0].numpy()\n",
    "    # roi x non_roi classes\n",
    "    wsi_class = class_name if wsi_image_path.find(class_name) > 0 else \"normal\"\n",
    "    patch_class = \"roi\" if np.max(np.unique(mask_np_img)) > 0 else 'non_roi'\n",
    "    # load the predicted image result\n",
    "    patch_results_dir = \"{}/{}/patch/{}x{}/{}\".format(results_dir, wsi_class, patch_size, patch_size, fname[0])\n",
    "    print(\"Patch results dir: \" + patch_results_dir)\n",
    "    unet_result_img = \"{}/01-unet_result/{}\".format(patch_results_dir, fname[0])\n",
    "    predicted_pil_img = Image.fromarray(np.zeros(mask_np_img.shape)) if patch_excludde_in_preprocessing else load_pil_image(unet_result_img, gray=True) if os.path.isfile(unet_result_img) else Image.fromarray(np.zeros(mask_np_img.shape))\n",
    "    predicted_np_img = np.copy(pil_to_np(predicted_pil_img)) \n",
    "    predicted_np_img = predicted_np_img * (1.0/255)\n",
    "    predicted_np_img = basic_threshold(predicted_np_img, threshold=threshold_prob, output_type=\"float\")\n",
    "    \n",
    "    # SAVE BINARY IMAGES\n",
    "    bin_images_path = '../../datasets/BONE_CHANNELS/results/BONE_CHANNELS__Size-640x640_Epoch-100_Images-464_Batch-1__random_distortion/testing/bones/patch/640x640/binary_images/'\n",
    "    predicted_np_img_255 = predicted_np_img * 255\n",
    "    mean = get_mean_props_area(predicted_np_img_255)\n",
    "    predicted_np_img_255 = remove_noise(predicted_np_img_255, mean)\n",
    "    predicted_np_img_255 = fill_components_contours(predicted_np_img_255)\n",
    "    \n",
    "    new_p = Image.fromarray(predicted_np_img_255)\n",
    "    if new_p.mode != 'RGB':\n",
    "        new_p = new_p.convert('RGB')\n",
    "    new_p.save(bin_images_path + fname[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative metrics for image-patches (512x512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "\n",
    "current_path = os.path.abspath('.')\n",
    "root_path = os.path.dirname(os.path.dirname(current_path))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from sourcecode.ORCA.orca_dataloader_512x512 import *\n",
    "from sourcecode.wsi_image_utils import *\n",
    "from sourcecode.evaluation_utils import *\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = \"../../datasets/ORCA_512x512\"\n",
    "dataset_dir_results = \"/media/dalifreire/DADOS/PhD/github/tumor_regions_segmentation/datasets/ORCA_512x512\"\n",
    "\n",
    "batch_size = 1\n",
    "patch_size = (512, 512)\n",
    "color_model = \"LAB\"\n",
    "dataloaders = create_dataloader(batch_size=batch_size, \n",
    "                                shuffle=False,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                color_model=color_model)\n",
    "\n",
    "dataset_train_size = len(dataloaders['train'].dataset)\n",
    "dataset_test_size = len(dataloaders['test'].dataset)\n",
    "print(\"-\")\n",
    "\n",
    "tile_size = 20\n",
    "magnification=0.625\n",
    "\n",
    "threshold_prob = 0.50\n",
    "threshold_itc = 200/(0.243 * pow(2, 5))\n",
    "\n",
    "wsi_images_dir_normal = \"{}/testing/normal/wsi\".format(dataset_dir)\n",
    "wsi_images_dir_tumor = \"{}/testing/tumor/wsi\".format(dataset_dir)\n",
    "\n",
    "trained_model_version = \"ORCA__Size-512x512_Epoch-352_Images-80_Batch-1__one_by_epoch\"\n",
    "results_dir=\"{}/results/{}/testing\".format(dataset_dir_results, trained_model_version)\n",
    "csv_file_path = \"{}/quantitative_analysis_{}.csv\".format(results_dir, threshold_prob)\n",
    "\n",
    "wsi_tissue_patches = {}\n",
    "with open(csv_file_path, mode='w') as medidas_file:\n",
    "\n",
    "    medidas_writer = csv.writer(medidas_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    medidas_writer.writerow(['wsi_image', 'patch_image', 'class', 'auc', 'accuracy', 'precision', 'f1/dice', 'jaccard', 'sensitivity/recall', 'specificity', 'pixels', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "    for batch_idx, (data, target, fname, original_size) in enumerate(dataloaders['test']):\n",
    "        \n",
    "        # load the mask image\n",
    "        mask_np_img = target[0].numpy()\n",
    "\n",
    "        # roi x non_roi classes\n",
    "        wsi_class = class_name\n",
    "        patch_class = \"roi\"                \n",
    "\n",
    "        # load the predicted image result\n",
    "        patch_results_dir = \"{}/{}/patch/{}x{}/{}\".format(results_dir, wsi_class, patch_size[0], patch_size[1], fname[0])\n",
    "        unet_result_img = \"{}/01-unet_result/{}\".format(patch_results_dir, fname[0])\n",
    "        predicted_pil_img = load_pil_image(unet_result_img, gray=True) if os.path.isfile(unet_result_img) else Image.fromarray(np.zeros(mask_np_img.shape))\n",
    "        predicted_np_img = np.copy(pil_to_np(predicted_pil_img))\n",
    "        predicted_np_img = predicted_np_img * (1.0/255)\n",
    "        predicted_np_img = basic_threshold(predicted_np_img, threshold=threshold_prob, output_type=\"uint8\")\n",
    "\n",
    "        predicted_labels = measure.label(predicted_np_img, connectivity=2)\n",
    "        predicted_np_img = np.zeros((predicted_np_img.shape[0], predicted_np_img.shape[1]))\n",
    "        labels = np.unique(predicted_labels)\n",
    "        properties = measure.regionprops(predicted_labels)\n",
    "        for lbl in range(1, np.max(labels)):\n",
    "            major_axis_length = properties[lbl-1].major_axis_length\n",
    "            if major_axis_length > threshold_itc:\n",
    "                predicted_np_img[predicted_labels == lbl] = 1\n",
    "\n",
    "\n",
    "        # metrics\n",
    "        auc = roc_auc_score(mask_np_img, predicted_np_img)\n",
    "        precision = precision_score(mask_np_img, predicted_np_img)\n",
    "        recall = recall_score(mask_np_img, predicted_np_img)\n",
    "        accuracy = accuracy_score(mask_np_img, predicted_np_img)\n",
    "        f1 = f1_score(mask_np_img, predicted_np_img)\n",
    "        specificity = specificity_score(mask_np_img, predicted_np_img)\n",
    "        jaccard = jaccard_score(mask_np_img, predicted_np_img)\n",
    "\n",
    "        total_pixels, tn, fp, fn, tp = tn_fp_fn_tp(mask_np_img, predicted_np_img)\n",
    "\n",
    "        print(fname[0])\n",
    "        print(\"Results for {:26} ({:7} - {:8} - {:04.2f} accuracy)\".format(fname[0], patch_class, \"unet\", accuracy))\n",
    "        #print(\"   Precision: \\t{}\".format(precision))\n",
    "        #print(\"   Recall/Sen: \\t{}\".format(recall))\n",
    "        #print(\"   F1/Dice: \\t{}\".format(f1))\n",
    "        #print(\"   Accuracy: \\t{}\".format(accuracy))\n",
    "        #print(\"   Specificity: {}\".format(specificity))\n",
    "        #print(\"   Jaccard: \\t{}\".format(jaccard))\n",
    "        #print(\"   TP = {} TN = {} FP = {} FN = {}\".format(tp, tn, fp, fn))\n",
    "        #print(\"-\")\n",
    "\n",
    "        medidas_writer.writerow([fname[0], '-', patch_class, auc, accuracy, precision, f1, jaccard, recall, specificity, total_pixels, tp, tn, fp, fn])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
