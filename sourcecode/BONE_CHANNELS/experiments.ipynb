{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating examples of augmented images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 14:03:12,773 :: INFO load_dataset :: [training] ../../datasets/BONE_CHANNELS/training\n",
      "2023-11-06 14:03:12,844 :: INFO load_dataset :: [training] ../../datasets/BONE_CHANNELS/training\n",
      "2023-11-06 14:03:12,913 :: INFO load_dataset :: [testing] ../../datasets/BONE_CHANNELS/testing\n",
      "2023-11-06 14:03:12,935 :: INFO create_dataloader :: Train images (640x640): 1258 augmentation: random\n",
      "2023-11-06 14:03:12,935 :: INFO create_dataloader :: Valid images (640x640): 315 augmentation: no_augmentation\n",
      "2023-11-06 14:03:12,936 :: INFO create_dataloader :: Test images (640x640): 464 augmentation: no_augmentation\n",
      "2023-11-06 14:03:12,936 :: INFO <module> :: 464\n",
      "2023-11-06 14:03:12,937 :: INFO <module> :: 1258\n"
     ]
    }
   ],
   "source": [
    "from bones_dataloader import *\n",
    "\n",
    "dataset_dir = \"../../datasets/BONE_CHANNELS\"\n",
    "\n",
    "batch_size = 6\n",
    "patch_size = (640, 640)\n",
    "color_model = \"RGB\"\n",
    "\n",
    "augmentation_strategy = \"random\" # \"no_augmentation\", \"color_augmentation\", \"inpainting_augmentation\", \"standard\", \"random\"\n",
    "augmentation = [None,\n",
    "                \"horizontal_flip\", \n",
    "                \"vertical_flip\", \n",
    "                \"rotation\", \n",
    "                \"transpose\", \n",
    "                \"elastic_transformation\", \n",
    "                \"grid_distortion\", \n",
    "                \"optical_distortion\",\n",
    "                #\"color_transfer\", \n",
    "                #\"inpainting\"]\n",
    "]\n",
    "\n",
    "dataloaders = create_dataloader(tile_size=\"{}x{}\".format(patch_size[0], patch_size[1]),\n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=True,\n",
    "                                img_input_size=patch_size,\n",
    "                                img_output_size=patch_size,\n",
    "                                dataset_dir=dataset_dir,\n",
    "                                color_model=color_model,\n",
    "                                augmentation=augmentation,\n",
    "                                augmentation_strategy=augmentation_strategy,\n",
    "                                start_epoch=1,\n",
    "                                validation_split=0.2)\n",
    "\n",
    "dataset_train_size = len(dataloaders['train'].dataset)\n",
    "dataset_test_size = len(dataloaders['test'].dataset)\n",
    "\n",
    "logger.info(dataset_test_size)\n",
    "logger.info(dataset_train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "  \n",
    "# open method used to open different extension image file \n",
    "image = Image.open(dataloaders['train'].dataset.samples[4][0])  \n",
    "mask = Image.open(dataloaders['train'].dataset.samples[4][1])  \n",
    "\n",
    "data_augmentation(image, mask, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "current_path = os.path.abspath('.')\n",
    "root_path = os.path.dirname(os.path.dirname(current_path))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from sourcecode.wsi_image_utils import *\n",
    "from sourcecode.logger_utils import *\n",
    "from sourcecode.GAN.model.networks import Generator\n",
    "from sourcecode.GAN.utils.tools import get_config, random_bbox, mask_image, is_image_file, default_loader, normalize, get_model_list\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from albumentations import (\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion,\n",
    "    OpticalDistortion\n",
    ")\n",
    "\n",
    "def data_augmentation(input_image, target_img, output_mask, img_input_size=(640, 640), img_output_size=(640, 640), aug=None, GAN_model=None):\n",
    "\n",
    "    image = TF.resize(input_image, size=img_output_size)\n",
    "    target_image = TF.resize(target_img, size=img_output_size) if target_img is not None else None\n",
    "    mask = TF.resize(output_mask, size=img_output_size) if output_mask is not None and np.any(\n",
    "        np.unique(pil_to_np(output_mask) > 0)) else None\n",
    "\n",
    "    used_augmentations = []\n",
    "    if True:\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if True:\n",
    "            image1 = TF.hflip(image)\n",
    "            mask1 = TF.hflip(mask) if mask is not None else None\n",
    "            used_augmentations.append(\"horizontal_flip\")\n",
    "            image1.save(\"temp/205_r3c7_hflip.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_hflip.png\")  \n",
    "\n",
    "        # Random vertical flipping\n",
    "        if True:\n",
    "            image1 = TF.vflip(image)\n",
    "            mask1 = TF.vflip(mask) if mask is not None else None\n",
    "            used_augmentations.append(\"vertical_flip\")\n",
    "            image1.save(\"temp/205_r3c7_vflip.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_vflip.png\")  \n",
    "\n",
    "        # Random rotation\n",
    "        if True:\n",
    "            augmented = RandomRotate90(p=1)(image=np.array(image),\n",
    "                                            mask=np.array(mask) if mask is not None else np.zeros(img_output_size))\n",
    "            image1 = Image.fromarray(augmented['image'])\n",
    "            mask1 = Image.fromarray(augmented['mask'])\n",
    "            used_augmentations.append(\"rotation\")\n",
    "            image1.save(\"temp/205_r3c7_rotation.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_rotation.png\") \n",
    "\n",
    "        # Random transpose\n",
    "        if True:\n",
    "            augmented = Transpose(p=1)(image=np.array(image),\n",
    "                                       mask=np.array(mask) if mask is not None else np.zeros(img_output_size))\n",
    "            image1 = Image.fromarray(augmented['image'])\n",
    "            mask1 = Image.fromarray(augmented['mask'])\n",
    "            used_augmentations.append(\"transpose\")\n",
    "            image1.save(\"temp/205_r3c7_transpose.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_transpose.png\") \n",
    "\n",
    "        # Random elastic transformation\n",
    "        if True:\n",
    "            alpha = random.randint(100, 200)\n",
    "            augmented = ElasticTransform(p=1, alpha=alpha, sigma=alpha * 0.05, alpha_affine=alpha * 0.03)(\n",
    "                image=np.array(image), mask=np.array(mask) if mask is not None else np.zeros(img_output_size))\n",
    "            image1 = Image.fromarray(augmented['image'])\n",
    "            mask1 = Image.fromarray(augmented['mask'])\n",
    "            used_augmentations.append(\"elastic_transformation\")\n",
    "            image1.save(\"temp/205_r3c7_elastic_transformation.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_elastic_transformation.png\") \n",
    "\n",
    "        # Random GridDistortion\n",
    "        if True:\n",
    "            augmented = GridDistortion(p=1)(image=np.array(image),\n",
    "                                            mask=np.array(mask) if mask is not None else np.zeros(img_output_size))\n",
    "            image1 = Image.fromarray(augmented['image'])\n",
    "            mask1 = Image.fromarray(augmented['mask'])\n",
    "            used_augmentations.append(\"grid_distortion\")\n",
    "            image1.save(\"temp/205_r3c7_grid_distortion.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_grid_distortion.png\") \n",
    "\n",
    "        # Random OpticalDistortion\n",
    "        if True:\n",
    "            augmented = OpticalDistortion(p=1, distort_limit=1, shift_limit=0.5)(image=np.array(image),\n",
    "                                                                                 mask=np.array(\n",
    "                                                                                     mask) if mask is not None else np.zeros(\n",
    "                                                                                     img_output_size))\n",
    "            image1 = Image.fromarray(augmented['image'])\n",
    "            mask1 = Image.fromarray(augmented['mask'])\n",
    "            used_augmentations.append(\"optical_distortion\")\n",
    "            image1.save(\"temp/205_r3c7_optical_distortion.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_optical_distortion.png\") \n",
    "\n",
    "        # Color transfer augmentation\n",
    "        if False:\n",
    "            \n",
    "            original_img_lab = TF.to_tensor(image).permute(1, 2, 0).numpy()\n",
    "            target_img_lab = TF.to_tensor(target_image).permute(1, 2, 0).numpy()\n",
    "\n",
    "            _, _, augmented_img = transfer_color(original_img_lab, target_img_lab)\n",
    "            image1 = transforms.ToPILImage()(torch.from_numpy(augmented_img).permute(2, 0, 1))\n",
    "            used_augmentations.append(\"color_transfer\")\n",
    "            image1.save(\"temp/205_r3c7_color_transfer.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_color_transfer.png\") \n",
    "\n",
    "        # Inpainting augmentation\n",
    "        if False:\n",
    "            \n",
    "            width, height = image.size\n",
    "            sourcecode_dir = os.path.dirname(os.path.abspath('.'))\n",
    "            config_file = os.path.join(sourcecode_dir, 'GAN/configs/config_imagenet_ocdc.yaml')\n",
    "            config = get_config(config_file)\n",
    "\n",
    "            # Setting the points for cropped image\n",
    "            crop_size = config['image_shape']\n",
    "            left = np.random.randint(0, width-crop_size[0])\n",
    "            top = np.random.randint(0, height-crop_size[1])\n",
    "\n",
    "            cropped_region = image.crop((left, top, left+crop_size[0], top+crop_size[1]))\n",
    "            cropped_region = pil_to_np(cropped_region)\n",
    "            cropped_region = lab_to_rgb(cropped_region)\n",
    "            cropped_region = transforms.ToTensor()(cropped_region)\n",
    "            inpainting_img = cropped_region.detach().clone().mul_(2).add_(-1)        # normalize between -1 and 1\n",
    "            inpainting_img = inpainting_img.unsqueeze(dim=0).to(dtype=torch.float32) # adds the batch channel\n",
    "            \n",
    "            bboxes = random_bbox(config, batch_size=inpainting_img.size(0))\n",
    "            inpainting_img, inpainting_mask = mask_image(inpainting_img, bboxes, config)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                GAN_model = nn.parallel.DataParallel(GAN_model)\n",
    "                inpainting_img = inpainting_img.cuda()\n",
    "                inpainting_mask = inpainting_mask.cuda()\n",
    "\n",
    "            # Inpainting inference\n",
    "            x1, x2, offset_flow = GAN_model(inpainting_img, inpainting_mask)\n",
    "            inpainted_result = x2 * inpainting_mask + inpainting_img * (1. - inpainting_mask)\n",
    "            inpainted_result = inpainted_result.squeeze(0).add_(1).div_(2) # renormalize between 0 and 1\n",
    "            inpainted_result = transforms.ToTensor()(rgb_to_lab(inpainted_result.permute(1, 2, 0).cpu().detach().numpy()))\n",
    "            \n",
    "            #viz_images = torch.stack([inpainting_img, inpainted_result.unsqueeze(dim=0).cuda()], dim=1)\n",
    "            #viz_images = viz_images.view(-1, *list(inpainting_img.size())[1:])\n",
    "            #vutils.save_image(viz_images,\n",
    "            #                    '/home/dalifreire/Pictures/augmentation/teste_%03d.png' % (random.randint(0, 999)),\n",
    "            #                    nrow=2 * 4,\n",
    "            #                    normalize=True)\n",
    "            \n",
    "            augmented_img = TF.to_tensor(image)\n",
    "            augmented_img[:, top:top+crop_size[1], left:left+crop_size[0]] = inpainted_result.squeeze(0)\n",
    "            image1 = transforms.ToPILImage()(augmented_img)\n",
    "            used_augmentations.append(\"inpainting\")\n",
    "            image1.save(\"temp/205_r3c7_inpainting.png\")  \n",
    "            mask1.save(\"temp/205_r3c7_mask_inpainting.png\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
